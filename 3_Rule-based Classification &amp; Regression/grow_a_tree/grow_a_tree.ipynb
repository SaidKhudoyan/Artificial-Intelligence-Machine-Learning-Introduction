{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72266b7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <h1 style=\"color: #3498db;\">Artificial Intelligence & Machine Learning</h1>\n",
    "    <h2 style=\"color: #3498db;\">DecisionTree Splitting Criteria</h2>\n",
    "</div>\n",
    "\n",
    "-------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95948eec",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; padding: 10px; border-radius: 5px;\">\n",
    "    <b>Authors:</b> K. Said<br>\n",
    "    <b>Date:</b> 08-09-2023\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color: #e6e6e6; padding: 10px; border-radius: 5px; margin-top: 10px;\">\n",
    "    <p>This notebook is part of the \"Artificial Intelligence & Machine Learning\" lecture material. The following copyright statement applies to all contents and code within this file.</p>\n",
    "    <b>Copyright statement:</b>\n",
    "    <p>This material, no matter whether in printed or electronic form, may be used for personal and non-commercial educational use only. Any reproduction of this manuscript, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors and lecturers.</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dfc02a",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Introduction</h1>\n",
    "\n",
    "-----------------------------------------------\n",
    "\n",
    "<h2 style=\"color:rgb(0,120,0)\">What you have learned so far</h2>\n",
    "\n",
    "--------------------------------------------------------------------\n",
    "\n",
    "Now that you arrived at one of the last exercises, let us have a short recap of what we have learned so far.\n",
    "In the first exercises we chose a dataset, analysed it and tried to gain some insights. In the steps afterwards we preprocessed the dataset, saved the preprocessed data and loaded it for our ML-models. Afterwards we made some predictions with \"relatively\" simple models and learned about different evaluation metrics for different subareas of AI (regression, classification, clustering).\n",
    "\n",
    "<h2 style=\"color:rgb(0,120,0)\">Our Task</h2>\n",
    "\n",
    "-------------------------------------------------\n",
    "\n",
    "In this notebook, our focus will be instead on different splitting criteria of DecisionTree Classifiers, such as Entropy and Gini. We will try to have a look at the created Decision-Trees and if possible, further increase their accuracy by using GridSearch.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f07a2a",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Splitting Criteria</h1>\n",
    "\n",
    "\n",
    "When using Decision Trees to predict some values/classes, we have to somehow decide when to split a dataset. The choise of how to split the data at each node is very crucial and is determined by a splitting criterion. \n",
    "Now what is the splitting criterion good for? Well, the splitting criterion is needed to measure how good the quality of a split was. Two commonly used criteria are Gini impurity and Entropy, often used in conjunction with Information Gain.\n",
    "\n",
    "And that's exactly what we are going to do in this notebook. We will play around with different splitting criteria and also try to finetune a Decision Tree Model to further increase the accuracy of our predictions. For this very purpose we will play around with the breast cancer dataset and try to predict wether an example should be labeled as cancer or non-cancer.\n",
    "\n",
    "**Sidenote**: The breast cancer dataset is freely available on kaggle. The features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. The dataset is also available by simply using sklearn's [load_breast_cancer()](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some necessary imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mod5_utils\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d5291",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size: larger; color: white; background-color: rgba(255, 165, 0, 0.6); border: 1px solid grey; padding: 5px 15px; border-radius: 8px; cursor: pointer;\">Load dataset</summary>\n",
    "\n",
    "<div style=\"background-color: rgba(255, 204, 153, 0.6); padding: 10px; border-radius: 5px;\">\n",
    "   As usual, we first start by loading our dataset and having a short look at it. In order to get everything in a compact view, we will use the <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html\" target=\"_blank\" style=\"color: blue; text-decoration: none;\">describe()</a> method of pandas.\n",
    "</div>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8f265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CODE CELL\n",
    "breast_cancer = load_breast_cancer()\n",
    "X = breast_cancer.data\n",
    "y = breast_cancer.target\n",
    "\n",
    "data = pd.DataFrame(data=X, columns=breast_cancer.feature_names)\n",
    "data['target'] = y\n",
    "\n",
    "display(data, data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfa7c85",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; padding: 10px; border-radius: 5px;\">\n",
    "    <b>Dataset Overview</b>: Based on above \"description\" of the dataset, we can not only see the mean of the dataset (for different features), but also multiple other things such as standard deviation, min, max and some more. Have a look at above table and try to get a feeling for the dataset before moving on.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "e62fb78c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size: larger; color: white; background-color: rgba(255, 165, 0, 0.6); border: 1px solid grey; padding: 5px 15px; border-radius: 8px; cursor: pointer;\">Split dataset</summary>\n",
    "\n",
    "<div style=\"background-color: rgba(255, 204, 153, 0.6); padding: 10px; border-radius: 5px;\">\n",
    "   Create a train and test dataset, where the train_dataset has 75% of all data. \n",
    "   If you did everything right, then the size of the dataset should look like this:\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "    \n",
    "\n",
    "**HINT:** Try to remember how we preprocessed the dataset in Module 3.\n",
    "    \n",
    "</div>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7394498d-4b53-4b0a-ab88-138075ce7663",
   "metadata": {},
   "source": [
    "# RECAP: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print(\"-\"*30)\n",
    "print(f\"X_Train: {X_train.shape}, X_Test: {X_test.shape}, Y_Train: {y_train.shape}, Y_Test{y_test.shape}\")\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split dataset --> Naming should be X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b163eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CODE CELL --> Tests wether you did everything right\n",
    "mod5_utils.data_split_test(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59254811",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size: larger; color: white; background-color: rgba(255, 165, 0, 0.6); border: 1px solid grey; padding: 5px 15px; border-radius: 8px; cursor: pointer;\">Information Gain and Entropy</summary>\n",
    "\n",
    "<div style=\"background-color: rgba(255, 204, 153, 0.6); padding: 10px; border-radius: 5px;\">\n",
    "Next up we want to load a simple DecisionTree Classifier and train it on the newly created Trainingset. However, as you know from the lectures, we have to know some kind of splitting criteria in order to correctly implement our model, which is why we want to use in this section the Entropy as our splitting criteria for our model.\n",
    "\n",
    "Here a short recap how the formula looked:\n",
    "    \n",
    "Information Gain (IG) Formula:\n",
    "$IG(D, A) = H(D) - H(D|A)$\n",
    "\n",
    "Entropy (H) Formula:\n",
    "\n",
    "$H(D) = - \\sum_{i=1}^{c} p_i \\log_2(p_i)$\n",
    "\n",
    "Where:\n",
    "- $IG(D, A)$ represents the Information Gain for a dataset $D$ and attribute $A$.\n",
    "- $H(D)$ represents the entropy of dataset $D$.\n",
    "- $H(D|A)$ represents the conditional entropy of dataset $D$ given attribute $A$.\n",
    "- $c$ represents the number of classes or outcomes in the dataset.\n",
    "- $p_i$ represents the probability of class $i$ in the dataset $D$.\n",
    "    \n",
    "    \n",
    "Don't worry, you don't have to implement everything from scratch, in order to make our life easier, we will use the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\" target=\"_blank\" style=\"color: blue; text-decoration: none;\">DecisionTreeClassifier()</a> class of sklearn. With this we can simply define the criteria. The parameters of the model should be set as follows:\n",
    "    \n",
    "- criterion = entropy\n",
    "- max_depth = 5\n",
    "- random_state = 42\n",
    "\n",
    ".\n",
    "</div>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f94f13ef-0bda-4c89-bbc9-a6b19e8df05d",
   "metadata": {},
   "source": [
    "# EXAMPLE: Create and fit a decision tree classifier using Information Gain and Entropy\n",
    "entropy_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)\n",
    "entropy_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9b7946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load model\n",
    "entropy_classifier = None\n",
    "\n",
    "# TODO: Fit the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573874f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CODE CELL --> Checks for model implementation\n",
    "mod5_utils.test_model(entropy_classifier, \"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a203992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CODE CELL ---> Visualization for your DecisionTree\n",
    "plt.figure(figsize=(15, 9))\n",
    "plot_tree(entropy_classifier, filled=True, feature_names=breast_cancer.feature_names, class_names=breast_cancer.target_names)\n",
    "plt.show()\n",
    "\n",
    "entropy_accuracy = entropy_classifier.score(X_test, y_test)\n",
    "print(f'Accuracy (Entropy): {entropy_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89ae43",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; padding: 10px; border-radius: 5px;\">\n",
    "    <b>DecisionTree with Entropy</b>: The result looks pretty nice, we got an accuracy of well above 90%. The interesting part might be how the Tree actually made it's splitting decisions. For this, have a closer look at above Tree that was plotted.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d26201",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size: larger; color: white; background-color: rgba(255, 165, 0, 0.6); border: 1px solid grey; padding: 5px 15px; border-radius: 8px; cursor: pointer;\">Gini</summary>\n",
    "\n",
    "<div style=\"background-color: rgba(255, 204, 153, 0.6); padding: 10px; border-radius: 5px;\">\n",
    "   Now that we saw the result of our classifier by using Entropy, let's try it this time but with Gini. But before we start, below is the formula in order to refresh your memory.\n",
    "\n",
    "Gini Impurity (GI) Formula:\n",
    "\n",
    "$GI(D) = 1 - \\sum_{i=1}^{c} p_i^2$\n",
    "\n",
    "Where:\n",
    "- $GI(D)$ represents the Gini Impurity of dataset $D$.\n",
    "- $c$ represents the number of classes or outcomes in the dataset.\n",
    "- $p_i$ represents the probability of class $i$ in the dataset $D$.\n",
    "\n",
    " \n",
    "Also here use the same parameters when loading the model, with the only difference being the criterion\n",
    "- criterion = gini\n",
    "- max_depth = 5\n",
    "- random_state = 42.\n",
    "</div>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98b7fef2-b694-4572-8e31-76233cf56951",
   "metadata": {},
   "source": [
    "# EXAMPLE: Gini Model\n",
    "gini_classifier = DecisionTreeClassifier(criterion='gini',max_depth=5, random_state=42)\n",
    "gini_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1991c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load model with gini\n",
    "gini_classifier = None\n",
    "\n",
    "# TODO: Fit the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93af5d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN CODE CELL --> Check correct model implementation\n",
    "mod5_utils.test_model(gini_classifier, \"gini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 9))\n",
    "plot_tree(gini_classifier, filled=True, feature_names=breast_cancer.feature_names, class_names=breast_cancer.target_names)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the classifier\n",
    "gini_accuracy = gini_classifier.score(X_test, y_test)\n",
    "print(f'Accuracy (Entropy): {gini_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f6381b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; padding: 10px; border-radius: 5px;\">\n",
    "    <b>DecisionTree with Gini</b>: Also here we got a pretty high accuracy (even the same). However, when comparing both trees, the structure does indeed look a bit different. Try to compare both trees and understand their differences.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b93f7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size: larger; color: white; background-color: rgba(255, 165, 0, 0.6); border: 1px solid grey; padding: 5px 15px; border-radius: 8px; cursor: pointer;\">Fine-Tune Parameters</summary>\n",
    "\n",
    "<div style=\"background-color: rgba(255, 204, 153, 0.6); padding: 10px; border-radius: 5px;\">\n",
    "   Now in this final step we want to see wether we can further improve the accuracy of our model. For this very purpose we will use <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\" target=\"_blank\" style=\"color: blue; text-decoration: none;\">GridSearch()</a> of sklearn. This will help us to finetune our model. Below are some parameters and their corresponding values that we already filled for you. Your task now is to further add/delete values and play around with it to find the best model. Try to beat the previous models.\n",
    "</div>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce25d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dt_model = DecisionTreeClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [1, 2],\n",
    "    'min_samples_split': [2, 3],\n",
    "    'min_samples_leaf': [1],\n",
    "    'criterion': [\"gini\", \"entropy\"]\n",
    "}\n",
    "grid_search = GridSearchCV(new_dt_model, param_grid, scoring='accuracy', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model_score = best_model.score(X_test, y_test)\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Model Accuracy:\", best_model_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc284587",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #f2f2f2; padding: 10px; border-radius: 5px;\">\n",
    "    <b>Results after fine-tuning</b>: If you were able to beat the previous models, try to understand why the results got better/worse when changing some parameters. And as a bonus, you might also want to plot the best DecisionTree Classifier.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee112c86",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a580b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
